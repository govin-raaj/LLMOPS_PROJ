embedding_model:
  provider: "google"
  model_name: "models/text-embedding-004"

retriever:
  top_k: 10
  search_type: "mmr"  
  fetch_k: 20  
  lambda_mult: 0.5

llm:
  groq:
    provider: "groq"
    model_name: "openai/gpt-oss-20b"
    temperature: 0
    max_output_tokens: 2048

  google:
    provider: "google"
    model_name: "gemini-2.0-flash"
    temperature: 0
    max_output_tokens: 2048
    
  huggingface:
    provider: "huggingface"
    model_name: "meta-llama/Llama-3.1-8B-Instruct"
    temperature: 0.2
    max_output_tokens: 2048